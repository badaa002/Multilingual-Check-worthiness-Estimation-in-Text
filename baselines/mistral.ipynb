{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client, Options\n",
    "from typing import Dict, Any, List\n",
    "import yaml\n",
    "import re\n",
    "import os\n",
    "from torch import Tensor\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "CHECKWORTHY_PROMPT = \"\"\"Given a sentence from a political debate or tweet, your task is to predict if it is fact check-worthy statement or not.\n",
    " Your response must always start with \"My response is: (yes or no based on your prediction)\"\n",
    " your prediction must be yes or no, and i wont accept you prediction to be \"I cannot determine\"\n",
    " Never write \"I'm and AI language model...\"\n",
    " Examples:\n",
    " fact check-worthy: The sky is blue.\n",
    " Not fact check-worthy: I like ice cream.\n",
    " fact check-worthy: The distance between the earth and the moon is 238,855 km.\n",
    " Not fact check-worthy: It made the best ratings in the history of television.\n",
    " fact check-worthy: The unemployment rate is 5.2% in Norway.\n",
    " Not fact check-worthy: I am the best president in the history of the United States.\n",
    "Sentence: {claim}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ollama:\n",
    "    \"\"\"A class for generating questions and interacting with the Ollama API.\"\"\"\n",
    "\n",
    "    def __init__(self, config_path: str = \"mistral.yaml\"):\n",
    "        \"\"\"Initializes the Ollama client and loads necessary configurations.\"\"\"\n",
    "        self._ollama_client = Client(timeout=20)\n",
    "        self._config_path = config_path\n",
    "        self._config = self._load_config()\n",
    "        self._stream = self._config.get(\"stream\", False)\n",
    "        self._model_name = self._config.get(\"model\", \"mistral\")\n",
    "        self._llm_options = self._get_llm_config()\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        \"\"\"Generate text using Ollama LLM for the given prompt.\n",
    "\n",
    "        Args:\n",
    "            prompt: Prompt for the LLM.\n",
    "\n",
    "        Returns:\n",
    "            Response text from an Ollama LLM.\n",
    "        \"\"\"\n",
    "        response = self._ollama_client.generate(\n",
    "            model=self._model_name,\n",
    "            prompt=prompt,\n",
    "            options=self._llm_options,\n",
    "            stream=self._stream,\n",
    "        )\n",
    "        return response.get(\"response\", \"\").strip()  # type: ignore\n",
    "\n",
    "    def _load_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Loads configuration from a YAML file.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the config file is not found.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with configuration values.\n",
    "        \"\"\"\n",
    "        if not os.path.isfile(self._config_path):\n",
    "            raise FileNotFoundError(f\"Config file {self._config_path} not found.\")\n",
    "        with open(self._config_path, \"r\") as file:\n",
    "            yaml_data = yaml.safe_load(file)\n",
    "        return yaml_data\n",
    "\n",
    "    def _get_llm_config(self) -> Options:\n",
    "        \"\"\"Extracts and returns the LLM (language learning model) configuration.\n",
    "\n",
    "        Returns:\n",
    "            An Options object with the LLM configuration.\n",
    "        \"\"\"\n",
    "        return Options(self._config.get(\"options\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = Ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/318 [00:16<29:38,  5.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m../data/processed/processed_CT24_checkworthy_english/processed_dev_test.tsv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m tqdm(df\u001b[39m.\u001b[39miterrows(), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(df)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     response \u001b[39m=\u001b[39m ollama\u001b[39m.\u001b[39;49mgenerate(CHECKWORTHY_PROMPT\u001b[39m.\u001b[39;49mformat(claim\u001b[39m=\u001b[39;49mrow[\u001b[39m\"\u001b[39;49m\u001b[39mtweet_text\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     response_words \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39msplit()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     answer \u001b[39m=\u001b[39m response_words[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mstrip(\u001b[39m\"\u001b[39m\u001b[39m.,\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mlower()\n",
      "\u001b[1;32m/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate text using Ollama LLM for the given prompt.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m        Response text from an Ollama LLM.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ollama_client\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_llm_options,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         stream\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sirenmelkevig/repositories/DAT550Project/baselines/mistral.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ollama/_client.py:126\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, model, prompt, system, template, context, stream, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model:\n\u001b[1;32m    124\u001b[0m   \u001b[39mraise\u001b[39;00m RequestError(\u001b[39m'\u001b[39m\u001b[39mmust provide a model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_stream(\n\u001b[1;32m    127\u001b[0m   \u001b[39m'\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    128\u001b[0m   \u001b[39m'\u001b[39;49m\u001b[39m/api/generate\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    129\u001b[0m   json\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    130\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m: model,\n\u001b[1;32m    131\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m'\u001b[39;49m: prompt,\n\u001b[1;32m    132\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m'\u001b[39;49m: system,\n\u001b[1;32m    133\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mtemplate\u001b[39;49m\u001b[39m'\u001b[39;49m: template,\n\u001b[1;32m    134\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m'\u001b[39;49m: context \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m    135\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m'\u001b[39;49m: stream,\n\u001b[1;32m    136\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m'\u001b[39;49m: raw,\n\u001b[1;32m    137\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mimages\u001b[39;49m\u001b[39m'\u001b[39;49m: [_encode_image(image) \u001b[39mfor\u001b[39;49;00m image \u001b[39min\u001b[39;49;00m images \u001b[39mor\u001b[39;49;00m []],\n\u001b[1;32m    138\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mformat\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    139\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39moptions\u001b[39;49m\u001b[39m'\u001b[39;49m: options \u001b[39mor\u001b[39;49;00m {},\n\u001b[1;32m    140\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mkeep_alive\u001b[39;49m\u001b[39m'\u001b[39;49m: keep_alive,\n\u001b[1;32m    141\u001b[0m   },\n\u001b[1;32m    142\u001b[0m   stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    143\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ollama/_client.py:97\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[0;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_request_stream\u001b[39m(\n\u001b[1;32m     92\u001b[0m   \u001b[39mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m   \u001b[39m*\u001b[39margs,\n\u001b[1;32m     94\u001b[0m   stream: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     95\u001b[0m   \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     96\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Mapping[\u001b[39mstr\u001b[39m, Any], Iterator[Mapping[\u001b[39mstr\u001b[39m, Any]]]:\n\u001b[0;32m---> 97\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mif\u001b[39;00m stream \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ollama/_client.py:68\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_request\u001b[39m(\u001b[39mself\u001b[39m, method: \u001b[39mstr\u001b[39m, url: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m httpx\u001b[39m.\u001b[39mResponse:\n\u001b[0;32m---> 68\u001b[0m   response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     70\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    812\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    814\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_request(\n\u001b[1;32m    815\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    816\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    825\u001b[0m     extensions\u001b[39m=\u001b[39mextensions,\n\u001b[1;32m    826\u001b[0m )\n\u001b[0;32m--> 827\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49mauth, follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1017\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[39m=\u001b[39m pool_request\u001b[39m.\u001b[39mwait_for_connection(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[39m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "listofpredicts = list()\n",
    "df = pd.read_csv(\n",
    "    \"../data/processed/processed_CT24_checkworthy_english/processed_dev_test.tsv\",\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    response = ollama.generate(CHECKWORTHY_PROMPT.format(claim=row[\"tweet_text\"]))\n",
    "    response_words = response.split()\n",
    "    answer = response_words[3].strip(\".,\").lower()\n",
    "    if answer == \"yes\" or answer == \"no\":\n",
    "        listofpredicts.append(response_words[3].strip(\".,\").lower())\n",
    "    else:\n",
    "        listofpredicts.append(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(listofpredicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8450755940916146\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(df[\"class_label\"].str.lower(), listofpredicts, average=\"weighted\")\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
