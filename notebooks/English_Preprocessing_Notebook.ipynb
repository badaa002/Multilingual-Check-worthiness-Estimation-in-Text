{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "Ijf3uJO2Rq6l",
        "outputId": "a6c61666-f12d-45bf-dc16-f3b2bc2ba9e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(22501, 3)\n",
            "Class Distribution:\n",
            "class_label\n",
            "No     75.943291\n",
            "Yes    24.056709\n",
            "Name: proportion, dtype: float64\n",
            "Missing values:\n",
            "Sentence_id    0\n",
            "tweet_text     0\n",
            "class_label    0\n",
            "text_length    0\n",
            "dtype: int64\n",
            "Number of duplicate rows: 0\n",
            "Number of Dutch tweets: 22501\n",
            "Number of tweets with URL: 0\n",
            "Number of tweets with noise: 680\n",
            "Number of tweets with non-ASCII characters: 49\n",
            "\n",
            "Examples:\n",
            "389                                                                                                                                                                                                                 It didn't look good the first two years when we had a Democratic president and Ã‚ Democratic Congress.\n",
            "620                                                                                                                                                           \"I just don't think it's the role of the United States to walk into a country and say, Ã¢â‚¬Å“we do it this way, so should you.Ã¢â‚¬Â I think we can help.\"\n",
            "684                                                                                                                                                                                                                    \"He says, Ã¢â€°Â¥Well, let's concede that the administration has been doing business with Noriega.\"\n",
            "881                                                                                                                                                                                                                               \"But itÃâ‚¬s not going to be dedicated by some federal bureaucracy in Washington, D.C.\"\n",
            "1485    \"They said even if we are the strongest if we donÃ¢â‚¬â„¢t do something if we don't have a clear vision of the military, if we don't stop extending our troops all around the world and nation building missions, then we're going to have a serious problem coming down the road, and I'm going to prevent that.\"\n",
            "Name: tweet_text, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>class_label</th>\n",
              "      <th>text_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30313</td>\n",
              "      <td>And so I know that this campaign has caused some questioning and worries on the part of many leaders across the globe.</td>\n",
              "      <td>No</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19099</td>\n",
              "      <td>\"Now, let's balance the budget and protect Medicare, Medicaid, education and the environment.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33964</td>\n",
              "      <td>I'd like to mention one thing.</td>\n",
              "      <td>No</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16871</td>\n",
              "      <td>I must remind him the Democrats have controlled the Congress for the last twenty-two years and they wrote all the tax bills.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13150</td>\n",
              "      <td>\"And to take a chance uh - now be - and not make every effort that we could make to provide for some control over these weapons, I think would be a great mistake.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence_id  \\\n",
              "0        30313   \n",
              "1        19099   \n",
              "2        33964   \n",
              "3        16871   \n",
              "4        13150   \n",
              "\n",
              "                                                                                                                                                            tweet_text  \\\n",
              "0                                               And so I know that this campaign has caused some questioning and worries on the part of many leaders across the globe.   \n",
              "1                                                                       \"Now, let's balance the budget and protect Medicare, Medicaid, education and the environment.\"   \n",
              "2                                                                                                                                       I'd like to mention one thing.   \n",
              "3                                         I must remind him the Democrats have controlled the Congress for the last twenty-two years and they wrote all the tax bills.   \n",
              "4  \"And to take a chance uh - now be - and not make every effort that we could make to provide for some control over these weapons, I think would be a great mistake.\"   \n",
              "\n",
              "  class_label  text_length  \n",
              "0          No          118  \n",
              "1          No           94  \n",
              "2          No           30  \n",
              "3         Yes          124  \n",
              "4          No          163  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "\n",
        "def contains_dutch(text):\n",
        "    dutch_pattern = re.compile(\"[a-zA-ZÀ-ÿ]+\")\n",
        "    return bool(dutch_pattern.search(text))\n",
        "\n",
        "\n",
        "def contains_url(text):\n",
        "    url_pattern = re.compile(\n",
        "        r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
        "    )\n",
        "    return bool(url_pattern.search(text))\n",
        "\n",
        "\n",
        "dutch_stopwords = [\n",
        "    \"Uh\",\n",
        "    \"Euh\",\n",
        "    \"Uhmm\",\n",
        "    \"Euhm\",\n",
        "    \"Wow\",\n",
        "    \"Wauw\",\n",
        "    \"Hé\",\n",
        "    \"Oh\",\n",
        "    \"O\",\n",
        "    \"Ach\",\n",
        "    \"Nou\",\n",
        "    \"Tja\",\n",
        "]\n",
        "\n",
        "\n",
        "def contains_noise(text):\n",
        "    # Check for short length\n",
        "    if len(text.split()) < 4:\n",
        "        return True\n",
        "\n",
        "    # Check for repetitive characters\n",
        "    if re.search(r\"(.)\\1{2,}\", text):\n",
        "        return True\n",
        "\n",
        "    # Dutch alphabet includes characters like 'ë', 'ü', 'é', 'ij', etc.\n",
        "    if not re.search(r\"[a-zA-ZÀ-ÿ]\", text) and \"ij\" not in text.lower():\n",
        "        return True\n",
        "\n",
        "    # Check for excessive punctuation\n",
        "    if re.search(r\"[!?.]{4,}\", text):\n",
        "        return True\n",
        "\n",
        "    # Check for excessive numbers\n",
        "    if re.search(r\"\\d{5,}\", text):\n",
        "        return True\n",
        "\n",
        "    # Check for URLs\n",
        "    if re.search(r\"http\\S+|www.\\S+\", text):\n",
        "        return True\n",
        "\n",
        "    # Check for common stopwords\n",
        "    if any(word in text.lower().split() for word in dutch_stopwords):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "# Exclude non-ASCII characters while preserving Dutch characters like 'ij', 'é', 'ë', etc.\n",
        "def check_non_ascii_tweets(df):\n",
        "    non_ascii_df = df[\n",
        "        df[\"tweet_text\"].apply(\n",
        "            lambda x: any(\n",
        "                (\n",
        "                    ord(char) > 127\n",
        "                    and not \"a\" <= char.lower() <= \"z\"\n",
        "                    and not \"à\" <= char.lower() <= \"ÿ\"\n",
        "                    and char.lower() not in [\"ij\", \"é\", \"ë\", \"è\", \"â\", \"ê\", \"ô\"]\n",
        "                )\n",
        "                for char in x\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        "    return non_ascii_df\n",
        "\n",
        "\n",
        "def data_exploration(train_df):\n",
        "    print(train_df.shape)\n",
        "    class_distribution = train_df[\"class_label\"].value_counts(normalize=True) * 100\n",
        "    print(\"Class Distribution:\")\n",
        "    print(class_distribution)\n",
        "\n",
        "    train_df[\"text_length\"] = train_df[\"tweet_text\"].apply(len)\n",
        "    missing_values = train_df.isnull().sum()\n",
        "    print(\"Missing values:\")\n",
        "    print(missing_values)\n",
        "    duplicate_rows = train_df.duplicated().sum()\n",
        "    print(f\"Number of duplicate rows: {duplicate_rows}\")\n",
        "\n",
        "    arabic_tweets = train_df[train_df[\"tweet_text\"].apply(contains_dutch)]\n",
        "    print(f\"Number of Dutch tweets: {len(arabic_tweets)}\")\n",
        "\n",
        "    tweets_with_url = train_df[train_df[\"tweet_text\"].apply(contains_url)]\n",
        "    print(f\"Number of tweets with URL: {len(tweets_with_url)}\")\n",
        "\n",
        "    tweets_with_noise = train_df[train_df[\"tweet_text\"].apply(contains_noise)]\n",
        "    print(f\"Number of tweets with noise: {len(tweets_with_noise)}\")\n",
        "\n",
        "    non_ascii_df = check_non_ascii_tweets(train_df)\n",
        "    print(f\"Number of tweets with non-ASCII characters: {len(non_ascii_df)}\\n\")\n",
        "    print(\"Examples:\")\n",
        "    print(non_ascii_df[\"tweet_text\"].head())\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def load(filename):\n",
        "    df = pd.read_csv(\n",
        "        filename,\n",
        "        sep=\"\\t\",\n",
        "        encoding=\"utf-8\",\n",
        "        names=[\"Sentence_id\", \"tweet_text\", \"class_label\"],\n",
        "        quoting=csv.QUOTE_NONE,\n",
        "        skiprows=1,\n",
        "        dtype={\"tweet_id\": \"Int64\"},\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "train_df = load(\n",
        "    \"../data/raw_clef2024-checkthat-lab-main-task1-data/CT24_checkworthy_english/CT24_checkworthy_english_train.tsv\"\n",
        ")\n",
        "data_exploration(train_df)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yirXTN3KMVo"
      },
      "source": [
        "* Handling 'ij' as a Special Case & other Special Cases\n",
        "* Handling html coding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_adHGkNyLDK"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "\n",
        "    Remove URLs: remove_urls\n",
        "    Replace Repeated Special Characters: replace_repeated_characters\n",
        "    Replace Commas and Double Quotes: replace_commas_and_quotes\n",
        "    Remove Ambiguous Words: remove_ambiguous_words\n",
        "    Remove Non-ASCII Characters: remove_non_ascii\n",
        "    Clean and normalize special cases like time formats (\"20u50\") and currency symbols (\"€\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RKn_lQ0vHXEq",
        "outputId": "f50c7df7-ac77-45e6-f367-a2a03621a772"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>class_label</th>\n",
              "      <th>text_length</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>mentions</th>\n",
              "      <th>text_length_category</th>\n",
              "      <th>class_label_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30313</td>\n",
              "      <td>And so I know that this campaign has caused some questioning and worries on the part of many leaders across the globe.</td>\n",
              "      <td>No</td>\n",
              "      <td>118</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>100+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19099</td>\n",
              "      <td>\"Now, let's balance the budget and protect Medicare, Medicaid, education and the environment.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>94</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>91-100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33964</td>\n",
              "      <td>I'd like to mention one thing.</td>\n",
              "      <td>No</td>\n",
              "      <td>30</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>21-30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16871</td>\n",
              "      <td>I must remind him the Democrats have controlled the Congress for the last twenty-two years and they wrote all the tax bills.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>124</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>100+</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13150</td>\n",
              "      <td>\"And to take a chance - now be - and not make every effort that we could make to provide for some control over these weapons, I think would be a great mistake.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>160</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>100+</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>32854</td>\n",
              "      <td>\"You know, children listen to what is being said.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>50</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>41-50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>12056</td>\n",
              "      <td>You can't carry a gun into a school.</td>\n",
              "      <td>No</td>\n",
              "      <td>36</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>31-40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>312</td>\n",
              "      <td>\"I don't think there's any question about that, and I resent it.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>65</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>61-70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>27238</td>\n",
              "      <td>\"Now, Governor Romney has taken a different approach throughout this campaign.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>79</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>71-80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>525</td>\n",
              "      <td>\"In my own state, for example, we now have that universal health care system, which the vice president opposes, I think very unwisely.\"</td>\n",
              "      <td>Yes</td>\n",
              "      <td>135</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>100+</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>503 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence_id  \\\n",
              "0          30313   \n",
              "1          19099   \n",
              "2          33964   \n",
              "3          16871   \n",
              "4          13150   \n",
              "..           ...   \n",
              "498        32854   \n",
              "499        12056   \n",
              "500          312   \n",
              "501        27238   \n",
              "502          525   \n",
              "\n",
              "                                                                                                                                                           tweet_text  \\\n",
              "0                                              And so I know that this campaign has caused some questioning and worries on the part of many leaders across the globe.   \n",
              "1                                                                      \"Now, let's balance the budget and protect Medicare, Medicaid, education and the environment.\"   \n",
              "2                                                                                                                                      I'd like to mention one thing.   \n",
              "3                                        I must remind him the Democrats have controlled the Congress for the last twenty-two years and they wrote all the tax bills.   \n",
              "4    \"And to take a chance - now be - and not make every effort that we could make to provide for some control over these weapons, I think would be a great mistake.\"   \n",
              "..                                                                                                                                                                ...   \n",
              "498                                                                                                                \"You know, children listen to what is being said.\"   \n",
              "499                                                                                                                              You can't carry a gun into a school.   \n",
              "500                                                                                                 \"I don't think there's any question about that, and I resent it.\"   \n",
              "501                                                                                   \"Now, Governor Romney has taken a different approach throughout this campaign.\"   \n",
              "502                           \"In my own state, for example, we now have that universal health care system, which the vice president opposes, I think very unwisely.\"   \n",
              "\n",
              "    class_label  text_length hashtags mentions text_length_category  \\\n",
              "0            No          118                                   100+   \n",
              "1            No           94                                 91-100   \n",
              "2            No           30                                  21-30   \n",
              "3           Yes          124                                   100+   \n",
              "4            No          160                                   100+   \n",
              "..          ...          ...      ...      ...                  ...   \n",
              "498          No           50                                  41-50   \n",
              "499          No           36                                  31-40   \n",
              "500          No           65                                  61-70   \n",
              "501          No           79                                  71-80   \n",
              "502         Yes          135                                   100+   \n",
              "\n",
              "     class_label_encoded  \n",
              "0                      0  \n",
              "1                      0  \n",
              "2                      0  \n",
              "3                      1  \n",
              "4                      0  \n",
              "..                   ...  \n",
              "498                    0  \n",
              "499                    0  \n",
              "500                    0  \n",
              "501                    0  \n",
              "502                    1  \n",
              "\n",
              "[503 rows x 8 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import regex as re\n",
        "import html\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def remove_urls(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def clean_corrupted_text(text):\n",
        "    text = re.sub(r\"(@\\w+\\s*)+\", \"@<USER> \", text)\n",
        "\n",
        "    # Fix URLs\n",
        "    text = re.sub(r\"h ps://\", \"https://\", text)\n",
        "\n",
        "    # Replace corrupted characters or remove them\n",
        "    text = text.replace(\"Bes el op  ijd!\", \"Bestel op tijd!\")\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_non_ascii(text):\n",
        "    # Remove non-ASCII characters except Dutch special characters\n",
        "    # Keep Dutch special characters while removing other non-ASCII characters\n",
        "    text = re.sub(\n",
        "        r'[^\\x00-\\x7F]|[^\\sa-zA-Z0-9#@<>\\[\\]\\(\\){}\\-_=+\\|:;\"\\',\\./\\?`~!\\$%^&\\*]',\n",
        "        \" \",\n",
        "        text,\n",
        "    )\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def replace_repeated_characters(text):\n",
        "    # Replace repeated special characters with a single occurrence\n",
        "    text = re.sub(r\"([,!?]){2,}\", r\"\\1\", text)\n",
        "    text = re.sub(r\"\\.{4,}\", \"...\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def replace_commas_and_quotes(text):\n",
        "    # Replace special characters like ---> and <--- with spaces\n",
        "    text = re.sub(r\"--->|<---\", \" \", text)\n",
        "    text = re.sub(r\"\\[.*?\\]\", \".\", text)  # Remove [] and its content\n",
        "    text = re.sub(r\"\\s+\\.\", \".\", text)  # Remove extra spaces in front of the dot\n",
        "    text = text.replace(\"/\", \"\").replace(\"  \", \" \").strip()  # Remove / dash\n",
        "\n",
        "    # Replace multiple double quotes with a single occurrence\n",
        "    text = re.sub(r'\"{2,}', '\"', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_ambiguous_words(text):\n",
        "    # Remove specific prefixes\n",
        "    text = re.sub(r\"LIVEBLOG \\|\", \"\", text)\n",
        "    text = re.sub(r\"LIVE \\|\", \"\", text)\n",
        "    text = re.sub(r\"LIVE\", \"\", text)\n",
        "    text = re.sub(r\"Live:\", \"\", text)\n",
        "    text = re.sub(r\"Live,\", \"\", text)\n",
        "\n",
        "    # Remove punctuation after 'Live'\n",
        "    text = re.sub(r\"Live[^\\s]*\", \"Live\", text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    for word in dutch_stopwords:\n",
        "        # Remove the ambiguous word and fix spaces\n",
        "        text = re.sub(r\"\\b{}\\b\".format(word), \"\", text, flags=re.IGNORECASE).strip()\n",
        "        if word.lower() != word:\n",
        "            # Remove commas at the start of the text or after spaces and double quotes at the start\n",
        "            text = re.sub(r\"^,\\s*\", \"\", text)\n",
        "            text = re.sub(r'^\"\\s*,\\s*', '\" ', text)\n",
        "            # Remove extra spaces at the start after double quote\n",
        "            text = re.sub(r'\"(\\s+)', '\"', text)\n",
        "            text = re.sub(r'(?<=^\"|^\\s)(\\w+)', lambda x: x.group(1).capitalize(), text)\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()  # Fix extra spaces\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def replace_html_entities(text):\n",
        "    # Replace common HTML entities\n",
        "    text = html.unescape(text)\n",
        "\n",
        "    # Replace special characters\n",
        "    replacements = {\n",
        "        \"&lt;\": \"<\",\n",
        "        \"&gt;\": \">\",\n",
        "        \"&amp;\": \"&\",\n",
        "        \"&quot;\": '\"',\n",
        "        \"&apos;\": \"'\",\n",
        "        \"&#39;\": \"'\",\n",
        "        \"&#34;\": '\"',\n",
        "        \"&#60;\": \"<\",\n",
        "        \"&#62;\": \">\",\n",
        "        \"&#38;\": \"&\",\n",
        "    }\n",
        "\n",
        "    for entity, char in replacements.items():\n",
        "        text = text.replace(entity, char)\n",
        "    return text\n",
        "\n",
        "\n",
        "def clean_special_cases(text):\n",
        "    text = re.sub(r\"’\", '\" ', text)\n",
        "    text = re.sub(r\"“\", '\" ', text)\n",
        "    text = re.sub(r\"”\", '\" ', text)\n",
        "\n",
        "    # Replace euro symbol with text and format amount\n",
        "    text = re.sub(r\"€(\\d+)\", r\"euro \\1\", text)\n",
        "    text = re.sub(r\"€(\\d+),(\\d+)\", r\"euro \\1.\\2\", text)\n",
        "\n",
        "    # Translate time format to 24-hour format\n",
        "    time_pattern = re.compile(r\"(\\d{1,2})u(\\d{2})\")\n",
        "    text = time_pattern.sub(r\"\\1:\\2\", text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Function to extract hashtags from tweet text\n",
        "def extract_hashtags(text):\n",
        "    hashtags = re.findall(r\"#(\\w+)\", text)\n",
        "    return \" \".join(hashtags)\n",
        "\n",
        "\n",
        "# Function to extract mentions from tweet text\n",
        "def extract_mentions(text):\n",
        "    mentions = re.findall(r\"@(\\w+)\", text)\n",
        "    return \" \".join(mentions)\n",
        "\n",
        "\n",
        "def remove_extra_spaces(text):\n",
        "    # Remove additional white spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def preprocessing(train_df):\n",
        "    train_df[\"hashtags\"] = train_df[\"tweet_text\"].apply(extract_hashtags)\n",
        "    train_df[\"mentions\"] = train_df[\"tweet_text\"].apply(extract_mentions)\n",
        "\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(clean_corrupted_text)\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(remove_urls)\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(replace_html_entities)\n",
        "\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(replace_commas_and_quotes)\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(replace_repeated_characters)\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(clean_special_cases)\n",
        "\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(remove_ambiguous_words)\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(remove_non_ascii)\n",
        "    train_df[\"tweet_text\"] = train_df[\"tweet_text\"].apply(remove_extra_spaces)\n",
        "\n",
        "    # Calculate text length\n",
        "    train_df[\"text_length\"] = train_df[\"tweet_text\"].apply(len)\n",
        "\n",
        "    # Categorize text length\n",
        "    bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, np.inf]\n",
        "    labels = [\n",
        "        \"0-10\",\n",
        "        \"11-20\",\n",
        "        \"21-30\",\n",
        "        \"31-40\",\n",
        "        \"41-50\",\n",
        "        \"51-60\",\n",
        "        \"61-70\",\n",
        "        \"71-80\",\n",
        "        \"81-90\",\n",
        "        \"91-100\",\n",
        "        \"100+\",\n",
        "    ]\n",
        "    train_df[\"text_length_category\"] = pd.cut(\n",
        "        train_df[\"text_length\"], bins=bins, labels=labels\n",
        "    )\n",
        "\n",
        "    # Label encode class label\n",
        "    label_encoder = LabelEncoder()\n",
        "    train_df[\"class_label_encoded\"] = label_encoder.fit_transform(\n",
        "        train_df[\"class_label\"]\n",
        "    )\n",
        "\n",
        "    train_df = train_df.drop(columns=[\"text_length\"])\n",
        "    # data_exploration(train_df)\n",
        "    return train_df\n",
        "\n",
        "\n",
        "preprocessing(train_df)\n",
        "train_df.head(503)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34SVKO4PXXoF"
      },
      "source": [
        "## Feature engineering\n",
        "  * Add Frequency of Hashtags\n",
        "  * Sentiment Analysis of Hashtags\n",
        "  * Topic Modeling with LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "lOzQKv5UXlmO",
        "outputId": "eaa73421-133e-4994-9887-ddb6ffc79961"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>class_label</th>\n",
              "      <th>text_length</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>mentions</th>\n",
              "      <th>text_length_category</th>\n",
              "      <th>class_label_encoded</th>\n",
              "      <th>hashtags_frequency</th>\n",
              "      <th>hashtags_sentiment</th>\n",
              "      <th>hashtags_topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30313</td>\n",
              "      <td>And so I know that this campaign has caused some questioning and worries on the part of many leaders across the globe.</td>\n",
              "      <td>No</td>\n",
              "      <td>118</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>100+</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19099</td>\n",
              "      <td>\"Now, let's balance the budget and protect Medicare, Medicaid, education and the environment.\"</td>\n",
              "      <td>No</td>\n",
              "      <td>94</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>91-100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33964</td>\n",
              "      <td>I'd like to mention one thing.</td>\n",
              "      <td>No</td>\n",
              "      <td>30</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>21-30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16871</td>\n",
              "      <td>I must remind him the Democrats have controlled the Congress for the last twenty-two years and they wrote all the tax bills.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>124</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>100+</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentence_id  \\\n",
              "0        30313   \n",
              "1        19099   \n",
              "2        33964   \n",
              "3        16871   \n",
              "\n",
              "                                                                                                                     tweet_text  \\\n",
              "0        And so I know that this campaign has caused some questioning and worries on the part of many leaders across the globe.   \n",
              "1                                \"Now, let's balance the budget and protect Medicare, Medicaid, education and the environment.\"   \n",
              "2                                                                                                I'd like to mention one thing.   \n",
              "3  I must remind him the Democrats have controlled the Congress for the last twenty-two years and they wrote all the tax bills.   \n",
              "\n",
              "  class_label  text_length hashtags mentions text_length_category  \\\n",
              "0          No          118                                   100+   \n",
              "1          No           94                                 91-100   \n",
              "2          No           30                                  21-30   \n",
              "3         Yes          124                                   100+   \n",
              "\n",
              "   class_label_encoded  hashtags_frequency  hashtags_sentiment  \\\n",
              "0                    0                   0                 0.0   \n",
              "1                    0                   0                 0.0   \n",
              "2                    0                   0                 0.0   \n",
              "3                    1                   0                 0.0   \n",
              "\n",
              "   hashtags_topics  \n",
              "0                0  \n",
              "1                0  \n",
              "2                0  \n",
              "3                0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Function to count frequency of hashtags\n",
        "def count_hashtags_frequency(text):\n",
        "    hashtags = re.findall(r\"#(\\w+)\", text)\n",
        "    return len(hashtags)\n",
        "\n",
        "\n",
        "# Function to analyze sentiment of hashtags\n",
        "def analyze_hashtag_sentiment(text):\n",
        "    hashtags = re.findall(r\"#(\\w+)\", text)\n",
        "    if hashtags:\n",
        "        sentiment_scores = [\n",
        "            TextBlob(hashtag).sentiment.polarity for hashtag in hashtags\n",
        "        ]\n",
        "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
        "        return avg_sentiment\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# Function for topic modeling with LDA\n",
        "def topic_modeling_with_lda(texts):\n",
        "    vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words=\"english\")\n",
        "    dtm = vectorizer.fit_transform(texts)\n",
        "\n",
        "    lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "    lda.fit(dtm)\n",
        "\n",
        "    topics = lda.transform(dtm)\n",
        "\n",
        "    return topics.argmax(axis=1)\n",
        "\n",
        "\n",
        "def add_additional_features(train_df):\n",
        "    # Count frequency of hashtags\n",
        "    train_df[\"hashtags_frequency\"] = train_df[\"tweet_text\"].apply(\n",
        "        count_hashtags_frequency\n",
        "    )\n",
        "\n",
        "    # Analyze sentiment of hashtags\n",
        "    train_df[\"hashtags_sentiment\"] = train_df[\"tweet_text\"].apply(\n",
        "        analyze_hashtag_sentiment\n",
        "    )\n",
        "\n",
        "    # Topic modeling with LDA\n",
        "    train_df[\"hashtags_topics\"] = 0\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "add_additional_features(train_df)\n",
        "train_df.head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYXmHbGL47XN"
      },
      "source": [
        "### Preprocessing dev and dev_test and saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wQO9-s5t4iqb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "def preprocess_dev_data(filename):\n",
        "    df = load(filename)\n",
        "    preprocessing(df)\n",
        "    add_additional_features(df)\n",
        "    return df\n",
        "\n",
        "\n",
        "def save_processed_dev_data(df, filepath):\n",
        "    df.to_csv(filepath, sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE)\n",
        "\n",
        "\n",
        "#'CT24_checkworthy_arabic/CT24_checkworthy_arabic_dev.tsv'\n",
        "dev_df = preprocess_dev_data(\n",
        "    \"../data/raw_clef2024-checkthat-lab-main-task1-data/CT24_checkworthy_english/CT24_checkworthy_english_dev.tsv\"\n",
        ")\n",
        "#'CT24_checkworthy_arabic/CT24_checkworthy_arabic_dev-test.tsv'\n",
        "dev_test_df = preprocess_dev_data(\n",
        "    \"../data/raw_clef2024-checkthat-lab-main-task1-data/CT24_checkworthy_english/CT24_checkworthy_english_dev-test.tsv\"\n",
        ")\n",
        "\n",
        "save_processed_dev_data(\n",
        "    dev_df, \"../data/processed/processed_CT24_checkworthy_english/processed_dev.tsv\"\n",
        ")\n",
        "save_processed_dev_data(\n",
        "    dev_test_df,\n",
        "    \"../data/processed/processed_CT24_checkworthy_english/processed_dev_test.tsv\",\n",
        ")\n",
        "save_processed_dev_data(\n",
        "    train_df, \"../data/processed/processed_CT24_checkworthy_english/processed_train.tsv\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
